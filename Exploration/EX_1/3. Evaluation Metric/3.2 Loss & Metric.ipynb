{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loss & Metric\n",
    "#### 🧠 인공지능 용어 정리\n",
    "\n",
    "---\n",
    "\n",
    "| 용어               | 설명 |\n",
    "|--------------------|------|\n",
    "| **Loss**           | 모델이 얼마나 틀렸는지를 나타내는 점수 (낮을수록 좋음) |\n",
    "| **Accuracy**       | 모델이 얼마나 정답을 맞혔는지 비율 (높을수록 좋음) |\n",
    "| **Metric**         | 성능을 평가하는 기준 (예: Accuracy, Precision 등) |\n",
    "| **Epoch**          | 전체 학습 데이터를 한 바퀴 다 학습한 횟수 |\n",
    "| **Batch**          | 데이터를 나눠서 조금씩 학습할 때의 묶음 단위 |\n",
    "| **Batch size**     | 한 번에 학습에 사용하는 데이터의 개수 |\n",
    "| **Gradient**       | Loss를 줄이기 위해 파라미터를 얼마나/어떻게 바꿔야 하는지 알려주는 값 |\n",
    "| **Backpropagation**| 오차를 뒤로 전달해 가중치를 조정하는 과정 |\n",
    "| **Optimizer**      | Loss를 줄이기 위해 가중치를 업데이트하는 방법 (예: SGD, Adam) |\n",
    "| **Learning rate**  | 가중치를 얼마나 바꿀지 정하는 속도 (너무 크면 불안정) |\n",
    "| **Underfitting**   | 모델이 너무 단순해서 학습이 잘 안 되는 상태 |\n",
    "| **Overfitting**    | 학습 데이터에만 너무 맞춰져서 실제 성능이 떨어지는 상태 |\n",
    "| **Train data**     | 모델을 학습시킬 때 사용하는 데이터 |\n",
    "| **Validation data**| 학습 도중 모델 성능을 확인하기 위해 사용하는 데이터 |\n",
    "| **Test data**      | 학습이 끝난 후 최종 성능을 평가하기 위해 사용하는 데이터 |\n",
    "| **Activation function** | 뉴런이 신호를 얼마나 보낼지 정하는 함수 (예: ReLU, Sigmoid) |\n",
    "| **Neural Network** | 뉴런들이 연결된 구조. 인공지능 모델의 뼈대 |\n",
    "| **Deep Learning**  | 신경망을 여러 층 쌓은, 더 복잡하고 강력한 모델 |\n",
    "| **Softmax**        | 모델의 출력값을 확률처럼 바꿔주는 함수 |\n",
    "| **Cross-Entropy**  | 정답일 확률이 높으면 Loss 작고, 틀릴수록 크게 벌점 주는 방식의 Loss |\n",
    "\n",
    "<hr style=\"opacity:0.2;\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "  \n",
    "#### 📘 3-2. Loss와 Metric\n",
    "\n",
    "<hr style=\"opacity:0.1;\">  \n",
    "  \n",
    "#### ❓ 들어가기에 앞서\n",
    "\n",
    "먼저 질문을 하나 드리겠습니다.  \n",
    "여러분은 **Loss**와 **Metric**의 차이를 설명할 수 있으신가요?\n",
    "\n",
    "예를 들어 **RMSE (Root Mean Square Error)** 는  \n",
    "Loss 함수로도 사용되며, 회귀 모델의 평가 척도(Metric)로도 사용됩니다.  \n",
    "단순히 **수식이 같다고** 해서 두 개념이 같은 건 아닙니다.\n",
    "\n",
    "> 핵심은 **사용 시점과 목적**이 다르다는 것!\n",
    "\n",
    "<hr style=\"opacity:0.1;\">  \n",
    "  \n",
    "#### 📌 핵심 개념 정리\n",
    "\n",
    "| 개념 | 설명 |\n",
    "|------|------|\n",
    "| **Loss** | 모델 학습 중 **train data를 기반**으로 계산. 모델의 파라미터를 업데이트할 때 사용됨 |\n",
    "| **Metric** | 학습이 끝난 후, **test data를 기반**으로 계산. 학습된 모델의 성능 평가에 사용됨 |\n",
    "\n",
    "<hr style=\"opacity:0.1;\">  \n",
    "  \n",
    "#### 🧠 예시: MNIST 손글씨 분류 모델\n",
    "\n",
    "- 모델의 **Loss 함수**: `Cross Entropy Loss`  \n",
    "- 모델의 **평가 Metric**: `Accuracy`\n",
    "\n",
    "> 같은 모델에 **Loss와 Metric이 다르게 적용된 이유**는 뭘까요?\n",
    "> 이유는 **Loss는 미분 가능해야 하지만, Metric은 그렇지 않을 수 있기 때문**입니다.  \n",
    "> 예를 들어, `Accuracy`는 이산적인 값으로 정의되므로 미분이 불가능합니다.  \n",
    "> 반면, `Cross Entropy Loss`는 연속적인 값으로 정의되어 미분 가능하며,  \n",
    "> 이를 통해 모델의 파라미터를 업데이트할 수 있습니다.\n",
    "\n",
    "<hr style=\"opacity:0.1;\">  \n",
    "  \n",
    "#### ⚠️ 왜 Accuracy를 Loss로 쓰면 안 될까?\n",
    "\n",
    "만약 학습 데이터 배치에 대해 계산한 `train accuracy`를  \n",
    "**Loss로 삼아서 학습**을 진행한다면?\n",
    "\n",
    "→ **그렇게 하면 안 됩니다!**\n",
    "\n",
    "<hr style=\"opacity:0.1;\">  \n",
    "  \n",
    "#### 🔗 더 알아보기\n",
    "\n",
    "이 주제를 잘 설명해주는 흥미로운 글이 있습니다:  \n",
    "**\"Loss vs Accuracy\"**\n",
    "\n",
    "(※ 링크 삽입 가능 시 아래처럼 표시)  \n",
    "🔗 [Loss vs Accuracy](https://modulabs.co.kr/blog/loss-versus-accuracy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ✅ Loss 함수 정리"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 1. 📏 평균 제곱 오차 (MSE, Mean Squared Error)\n",
    "\n",
    "- **언제 사용?** → 숫자를 예측할 때 (예: 키, 온도, 점수 등)\n",
    "- **수식**  \n",
    "  $$\n",
    "  \\text{Loss} = \\frac{1}{n} \\sum (y - \\hat{y})^2\n",
    "  $$\n",
    "- **뜻** → 정답과 예측의 차이를 제곱해서 평균을 낸 것\n",
    "- **특징**\n",
    "  - 예측이 정답에서 멀수록 Loss가 크게 나옴\n",
    "  - 차이를 제곱하므로, **많이 틀린 건 더 크게 벌점**\n",
    "  - **Loss가 작아질수록 모델이 정답에 가까워짐**\n",
    "\n",
    "<hr style=\"opacity:0.2;\">\n",
    "\n",
    "### 2. 🎯 교차 엔트로피 (Cross-Entropy)\n",
    "\n",
    "- **언제 사용?** → 분류 문제일 때 (예: 고양이 vs 강아지, 스팸 vs 일반 메일 등)\n",
    "- **수식**  \n",
    "  $$\n",
    "  \\text{Loss} = -\\sum y \\cdot \\log(\\hat{y})\n",
    "  $$\n",
    "- **뜻** → 정답에 해당하는 클래스의 예측 확률이 **높을수록 Loss가 작아짐**\n",
    "- **특징**\n",
    "  - **정답에 확신을 갖고 맞히면** Loss ↓\n",
    "  - **틀린 답에 높은 확률을 주면** Loss ↑\n",
    "  - 모델의 \"확신도\"까지 반영함\n",
    "\n",
    "<hr style=\"opacity:0.2;\">\n",
    "\n",
    "### 📌 정리 비교\n",
    "\n",
    "| 구분          | MSE                            | Cross-Entropy                           |\n",
    "|---------------|--------------------------------|------------------------------------------|\n",
    "| 문제 유형     | 숫자 예측 (회귀)              | 정답을 고르는 문제 (분류)              |\n",
    "| 계산 방식     | 오차를 제곱해서 평균           | 정답 확률의 로그를 사용                |\n",
    "| 특징          | 많이 틀리면 크게 벌점          | 확신도까지 따져서 벌점 부여            |\n",
    "| 예시          | 키 예측, 가격 예측 등         | 고양이/개 구분, 스팸메일 판별 등       |\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ✅ Accuracy 함수 정리"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy 는 우리의 모델이 어떤 성능을 보이고 있는지 표현하는 지표 중 하나 입니다. 다른 지표들이 궁금하다면 여기 를 참고해보세요. Accuracy의 정의는 다음과 같습니다.\n",
    "\n",
    "$$ \\text{Accuracy}=\\frac{\\text{No of correct predictions}}{\\text{Total no of predictions}} $$\n",
    "\n",
    "Accuracy는 전체 예측 중에서 올바르게 예측된 비율을 나타냅니다.\n",
    "대부분의 경우 loss 가 감소하면 정확도가 증가하는 경향성을 관찰할 수 있습니다. 하지만, 아래 예시와 같이 전혀 다른 사실이 나타나는 경우가 있습니다.\n",
    "\n",
    "\n",
    "https://kharshit.github.io/blog/2018/12/07/loss-vs-accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 🖼️ Loss vs Accuracy 시각 자료\n",
    "\n",
    "모델 학습에서 Loss는 줄어들고 있는데, Accuracy는 일정하거나 오히려 떨어질 수도 있습니다.  \n",
    "두 지표는 **같은 방향으로만 움직이지 않을 수 있다는 점**을 시각적으로 보여주는 좋은 예시입니다.\n",
    "\n",
    "<img src=\"https://kharshit.github.io/img/lossVsAccuracy.png\" width=\"800\">\n",
    "\n",
    "<hr style=\"opacity:0.3;\">\n",
    "\n",
    "\n",
    "Case 2의 경우 loss 가 증가했음에도 정확도는 오히려 감소하지 않고 상승하였습니다. 도대체 무슨 상황이 벌어진 걸까요?\n",
    "\n",
    "이런 현상은 정확도와 손실함수가 각각 서로 다른 대상을 측정하기 때문에 발생합니다. Cross-entropy 은 클래스 레이블에 더 가까운 예측할 수록 더 낮은 loss 값을 제공합니다. 반면 정확도는 특정 샘플에 대해 이진화된 정답/오답을 가름합니다. 즉 여기에서 loss 는 정답에 경우 1에 가까울 수록, 오답의 경우 0에 가깝도록 설정된 연속적인 변수인데 반해, 정확도는 단계별로 나뉘어 떨어지는 이산적인 표현을 나타냅니다. 이는 위 그림에서 loss와 정확도의 값을 계산하는 과정에서 확인할 수 있습니다. 즉, 손실 함수와 지표가 최적화 시키고 싶은 대상이 서로 다르기 때문에 발생하는 문제로 볼 수 있습니다.\n",
    "\n",
    "하나는 높은 정확도와 높은 loss 값을 가지고, 다른 하나는 낮은 정확도와 낮은 loss 값을 가지는 두 종류 모델이 있을때, 우리는 어떤 모델을 선택할까요? 정확도와 손실함수 중 어떤 것을 확인할 것인지 정하기 전에, 스스로 물어봐야할 질문은 ‘정확도와 손실함수 중에 어떤 것이 중요하다고 생각하는가?’ 입니다. 손실함수를 중요하게 생각한다면 앞선 두 모델 중 더 작은 손실함수값을 가진 모델을 선택하세요. 만약 정확도가 중요하다면 더 높은 정확도를 보인 모델을 선택하면 됩니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ✅ Metric 함수를 Loss 로 사용하면 안되는 이유"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 📌 Loss 함수 vs Metric 함수 차이점\n",
    "\n",
    "---\n",
    "\n",
    "| 구분           | Loss 함수                                  | Metric 함수                                |\n",
    "|----------------|--------------------------------------------|--------------------------------------------|\n",
    "| **역할**       | 모델이 얼마나 틀렸는지 계산 (학습에 사용) | 모델이 얼마나 잘하고 있는지 평가 (모니터링용) |\n",
    "| **사용 목적**  | 모델이 더 나아지도록 학습시키는 기준      | 성능을 사람이 이해하기 쉬운 지표로 보여줌 |\n",
    "| **예시**       | MSE, Cross-Entropy                         | Accuracy, Precision, Recall                |\n",
    "| **학습 영향**  | **Optimizer가 Loss 값을 줄이도록 학습함** | 학습에는 직접 관여하지 않음               |\n",
    "| **계산 방식**  | 예측값과 정답 사이의 차이로 계산          | 예측이 얼마나 맞았는지를 비율로 계산      |\n",
    "| **주요 용도**  | 파라미터 업데이트 (역전파에 사용)         | 성능 비교, 시각화, 모델 선택 기준 등      |\n",
    "\n",
    "<hr style=\"opacity:0.2;\">\n",
    "\n",
    "🧠 쉽게 예를 들면?\n",
    "Loss 함수는 모델에게 말해요:\n",
    "\n",
    "\"너 이만큼 틀렸어. 다음엔 더 잘해보자!\" → 훈련을 위한 기준\n",
    "\n",
    "Metric 함수는 사람에게 말해요:\n",
    "\n",
    "\"현재 정답률은 85%입니다.\" → 성능 확인용 지표"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 📈일반적인 손실 함수 경향성"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 📉 일반적인 손실 함수의 경향성과 학습 곡선 (Training Curve)\n",
    "\n",
    "---\n",
    "\n",
    "머신러닝의 다양한 학습 상황을 이해하기 위해 **학습 곡선 (Training Curve)** 을 그려보면  \n",
    "몇 가지 중요한 **경향성**을 관찰할 수 있습니다.\n",
    "\n",
    "---\n",
    "\n",
    "### ✅ 학습 곡선이란?\n",
    "\n",
    "- **학습 손실 (Train Loss)**, **검증 손실 (Validation Loss)**  \n",
    "- **학습 정확도 (Train Accuracy)**, **검증 정확도 (Validation Accuracy)**  \n",
    "이들의 **변화를 시간(Epoch) 순으로 시각화한 그래프**입니다.\n",
    "\n",
    "---\n",
    "\n",
    "### 🧩 왜 필요한가요?\n",
    "\n",
    "- **학습이 잘 되고 있는지**,  \n",
    "- **과적합(overfitting)이나 과소적합(underfitting)이 발생하고 있는지**,  \n",
    "- **모델이 언제부터 성능이 떨어졌는지** 등을 시각적으로 확인할 수 있습니다.\n",
    "\n",
    "---\n",
    "\n",
    "### 🖼️ 시각화 방법\n",
    "\n",
    "보통 다음과 같이 **두 개의 그래프**로 나누어 그립니다:\n",
    "\n",
    "1. **Loss 그래프**\n",
    "   - Y축: 손실 값 (Loss)\n",
    "   - X축: Epoch (학습 횟수)\n",
    "   - 학습 손실과 검증 손실을 함께 표시\n",
    "\n",
    "2. **Accuracy 그래프**\n",
    "   - Y축: 정확도 (%)\n",
    "   - X축: Epoch\n",
    "   - 학습 정확도와 검증 정확도를 함께 표시\n",
    "\n",
    "> 이렇게 나누면 각 지표의 **경향성**을 보다 명확하게 파악할 수 있습니다.\n",
    "\n",
    "---\n",
    "\n",
    "### 📌 주요 경향성 예시\n",
    "\n",
    "| 상황 | 손실(Loss) 경향 | 정확도(Accuracy) 경향 | 해석 |\n",
    "|------|------------------|------------------------|------|\n",
    "| 정상 학습 | 둘 다 점차 감소 | 둘 다 점차 증가 | 학습이 잘 진행되고 있음 |\n",
    "| 과적합 | 학습 손실은 감소, 검증 손실은 증가 | 학습 정확도는 증가, 검증 정확도는 감소 | 모델이 학습 데이터에만 과도하게 맞춤 |\n",
    "| 과소적합 | 손실 변화 거의 없음 | 정확도도 낮고 변화 없음 | 모델이 충분히 학습하지 못함 |\n",
    "| 학습률 너무 큼 | Loss가 요동침 | Accuracy도 불안정 | 학습이 불안정하게 진행됨 |\n",
    "\n",
    "---\n",
    "\n",
    "### 💡 팁\n",
    "\n",
    "- 학습 곡선을 꾸준히 확인하며, **조기 종료(Early Stopping)**, **학습률 조절**, **모델 구조 변경**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loss & Metric 진단하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 📊 학습 곡선과 Train / Validation Set 해석\n",
    "\n",
    "---\n",
    "\n",
    "1. **Train vs Validation Loss - 그래프 1**  \n",
    "<img src=\"https://blog-web.modulabs.co.kr/wp-content/uploads/2024/03/loss_1.png\" width=\"500\">\n",
    "\n",
    "- **해석**  \n",
    "  - Train Set과 Validation Set 사이의 연관성이 낮아 보입니다.  \n",
    "  - 모델이 validation 데이터에 일반화되지 못하고 있습니다.  \n",
    "  - ➤ **더 다양한 데이터를 수집**하거나, **데이터 분포를 맞춰야 할 시점**입니다.\n",
    "\n",
    "---\n",
    "\n",
    "2. **Train vs Validation Loss - 그래프 2**  \n",
    "<img src=\"https://blog-web.modulabs.co.kr/wp-content/uploads/2024/03/loss_2.png\" width=\"500\">\n",
    "\n",
    "- **해석**  \n",
    "  - Train Set과 Validation Set이 공유하는 패턴이 거의 없어 보입니다.  \n",
    "  - 모델이 유의미한 패턴을 학습하지 못하고 있습니다.  \n",
    "  - ➤ 이럴 땐 **모델 구조 개선** 또는 **데이터 전처리 점검**이 필요할 수 있습니다.\n",
    "\n",
    "---\n",
    "\n",
    "3. **Train vs Validation Loss - 그래프 3**  \n",
    "<img src=\"https://blog-web.modulabs.co.kr/wp-content/uploads/2024/03/loss_3.png\" width=\"500\">\n",
    "\n",
    "- **해석**  \n",
    "  - Validation Set의 특징이 오히려 Train Set보다 덜 복잡해 보입니다.  \n",
    "  - 일부 구간에서 **Validation 성능이 오히려 더 높게 나오는 역전 현상**이 발생합니다.  \n",
    "  - ➤ 데이터셋 구성이 편향됐을 가능성. 데이터 재구성이 필요합니다.\n",
    "\n",
    "<hr style=\"opacity:0.2;\">\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 📈 학습 지표(Metric) 곡선 해석\n",
    "\n",
    "---\n",
    "\n",
    "1. **Train vs Test Accuracy - 그래프 1**  \n",
    "<img src=\"https://blog-web.modulabs.co.kr/wp-content/uploads/2024/03/metric_1.png\" width=\"500\">\n",
    "\n",
    "- **해석**  \n",
    "  - 학습 초기, 최적화 과정에서 일부 돌출된 지점이 나타납니다.  \n",
    "  - 약간의 추가 학습(epoch)을 거치며 **train-test 곡선의 간극이 좁아졌습니다.**  \n",
    "  - ➤ 전반적으로 **안정적이고 정상적인 학습 진행**으로 보입니다.\n",
    "\n",
    "---\n",
    "\n",
    "2. **Train vs Test Accuracy - 그래프 2**  \n",
    "<img src=\"https://blog-web.modulabs.co.kr/wp-content/uploads/2024/03/metric_2.png\" width=\"500\">\n",
    "\n",
    "- **해석**  \n",
    "  - 모델이 **유의미한 패턴을 찾지 못해** train accuracy가 약 50% 근처에 머물러 있습니다.  \n",
    "  - 반면, test accuracy와의 차이는 점점 커지며 **성능이 악화되고 있습니다.**  \n",
    "  - ➤ **과대적합(Overfitting)** 가능성이 의심됩니다.\n",
    "\n",
    "---\n",
    "\n",
    "3. **Train vs Test Accuracy - 그래프 3**  \n",
    "<img src=\"https://blog-web.modulabs.co.kr/wp-content/uploads/2024/03/metric_3.png\" width=\"500\">\n",
    "\n",
    "- **해석**  \n",
    "  - 학습 과정 내내 지표가 약 50% 근처에서 **진동하며 정체**되어 있습니다.  \n",
    "  - 가중치가 계속 갱신되고 있음에도 불구하고 **성능 향상이 거의 없습니다.**  \n",
    "  - ➤ **Vanishing Gradient(기울기 소실)** 문제가 발생했을 가능성이 높습니다.\n",
    "\n",
    "<hr style=\"opacity:0.2;\">\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
