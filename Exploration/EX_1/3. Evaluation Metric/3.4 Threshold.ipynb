{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 📈 Threshold 변화와 모델 성능 평가\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 🧪 암환자 분류 모델에서의 Threshold\n",
    "\n",
    "이전 예제에서 우리는 **암인지 아닌지를 분류하는 이진 분류 모델**을 학습했습니다.  \n",
    "이 모델은 각 환자에 대해 **\"양성일 확률\"**을 예측합니다.\n",
    "\n",
    "예를 들어, 어떤 환자에 대해 모델이  \n",
    "> \"이 사람은 0.7 확률로 암일 것 같아요.\"  \n",
    "라고 예측했다면, 우리는 이 값을 기준으로  \n",
    "**양성(암)인지 음성(정상)인지** 를 판단해야 합니다.\n",
    "\n",
    "이때 기준선이 되는 수치를 **Threshold (임계값)** 이라고 부릅니다.\n",
    "\n",
    "<hr style=\"opacity:0.2;\">\n",
    "\n",
    "#### 🎯 Threshold를 바꾸면 무슨 일이 생기나요?\n",
    "\n",
    "보통은 **0.5 이상이면 양성, 아니면 음성** 으로 분류하지만,  \n",
    "만약 **0.3만 넘으면 양성으로 판단한다면?**\n",
    "\n",
    "- 더 많은 환자를 **양성(암)** 이라고 예측하게 됩니다.\n",
    "- 암 환자를 **놓칠 확률(FN)** 이 줄어들고, **Recall** 이 올라갑니다.\n",
    "- 대신, 정상인도 암으로 잘못 예측할 확률(FP)이 늘어나서 **Precision** 은 낮아질 수 있습니다.\n",
    "\n",
    "> 💡 즉, **Threshold를 어떻게 설정하느냐에 따라 모델의 성능 지표가 달라집니다.**  \n",
    "> 모델의 구조나 파라미터는 그대로인데, **출력 해석 방식만 바꾼 것** 인데도 성능이 바뀌는 거죠.\n",
    "\n",
    "<hr style=\"opacity:0.2;\">\n",
    "\n",
    "#### 📌 이 말은 곧…\n",
    "\n",
    "모델의 성능이 **F1 Score 하나로 완전히 표현되지 않을 수 있다는 의미** 입니다.  \n",
    "Threshold가 고정돼 있다면 F1 Score는 유효하지만,  \n",
    "**Threshold를 변화시킬 수 있는 상황에서는 더 넓은 관점의 평가 지표** 가 필요합니다.\n",
    "\n",
    "<hr style=\"opacity:0.2;\">\n",
    "\n",
    "#### 📊 그래서 사용하는 두 가지 방법\n",
    "\n",
    "1. **PR Curve (Precision-Recall Curve)**  \n",
    "   - 다양한 Threshold에서의 **Precision** 과 **Recall** 값을 그래프로 표현  \n",
    "   - 특히 **양성 클래스가 중요한 경우** 유용함\n",
    "\n",
    "2. **ROC Curve (Receiver Operating Characteristic Curve)**  \n",
    "   - 다양한 Threshold에서의 **TPR(Recall)** 과 **FPR(False Positive Rate)** 의 관계를 표현  \n",
    "   - 일반적으로 전체적인 분류 성능을 평가할 때 사용\n",
    "\n",
    "<hr style=\"opacity:0.2;\">\n",
    "\n",
    "#### 🔍 정리\n",
    "\n",
    "- Threshold가 달라지면 모델의 출력 해석이 달라지고,  \n",
    "  성능 지표(Accuracy, Precision, Recall, F1 등)도 달라집니다.\n",
    "- 모델의 전체적인 성능을 종합적으로 평가하고 싶다면  \n",
    "  **PR 커브** 와 **ROC 커브** 를 함께 살펴봐야 합니다.\n",
    "\n",
    "<hr style=\"opacity:0.2;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 코드를 통한 실습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(150, 4)\n"
     ]
    }
   ],
   "source": [
    "# 사이킷런에서 제공하는 데이터셋을 사용하는 방법을 알아봅니다.\n",
    "# 사이킷런에서 제공하는 데이터셋은 딕셔너리 형태로 되어 있습니다.\n",
    "# 데이터셋을 불러오고, 데이터셋의 형태를 확인해봅니다.\n",
    "# 데이터셋을 불러오는 방법은 datasets 모듈을 불러오고, load_데이터셋명() 함수를 사용합니다.\n",
    "from sklearn import datasets\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "iris = datasets.load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "print(X.shape)  # 4개의 feature를 가진 150개의 데이터입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(150, 804)\n"
     ]
    }
   ],
   "source": [
    "random_state = np.random.RandomState(0) # seed를 고정합니다.\n",
    "n_samples, n_features = X.shape # 150개의 데이터와 4개의 feature가 있습니다.\n",
    "X = np.c_[X, random_state.randn(n_samples, 200 * n_features)] # np.c_[]를 사용하여 feature를 추가합니다.\n",
    "# X는 random_state.randn(n_samples, 200 * n_features)를 추가하게 되면 804개의 feature를 가진 150개의 데이터가 됩니다.\n",
    "\n",
    "print(X.shape)  # 804개의 feature를 가진 150개의 데이터가 되었습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련, 테스트 셋에 사용된 라벨의 종류: {np.int64(0), np.int64(1)} \n",
      "훈련 데이터 shape   : (50, 804)\n",
      "테스트 데이터 shape : (50, 804)\n"
     ]
    }
   ],
   "source": [
    "#- 0, 1 라벨에 속하는 붓꽃 샘플만 사용하도록 제한합니다.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X[y < 2], y[y < 2],\n",
    "                                                    test_size=.5,\n",
    "                                                    random_state=random_state)\n",
    "\n",
    "print(\"훈련, 테스트 셋에 사용된 라벨의 종류: {} \".format( set(y_test)))\n",
    "print(\"훈련 데이터 shape   :\", X_train.shape)\n",
    "print(\"테스트 데이터 shape :\", X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.48"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 두개의 라벨로 나뉜 데이터를 가지고, SVM(Support Vector Machine)을 사용하여 분류를 해봅니다.\n",
    "# SVM은 데이터를 분류하는 경계선을 찾아주는 알고리즘입니다.\n",
    "# SVM은 선형 분류와 비선형 분류를 모두 지원합니다.\n",
    "# 여기서는 비선형 분류를 위해 kernel='poly'를 사용합니다.\n",
    "# test 데이터에 대한 정확도를 출력합니다.\n",
    "from sklearn import svm\n",
    "\n",
    "classifier = svm.SVC(kernel='poly', random_state=random_state)\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "classifier.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# kernel='poly' 대신 kernel='linear'를 사용하면 선형 분류를 수행합니다.\n",
    "# test 데이터에 대한 정확도를 출력합니다.\n",
    "classifier = svm.SVC(kernel='linear', random_state=random_state)\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "classifier.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0,\n",
       "       0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1,\n",
       "       0, 1, 1, 1, 0, 1])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# classifer.predict() 함수를 사용하여 테스트 데이터에 대한 예측을 수행합니다.\n",
    "classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0,\n",
       "       0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1,\n",
       "       0, 1, 1, 0, 1, 0])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.29512751  0.28798352  0.17635465  0.19056886  0.38391605 -0.30841065\n",
      " -0.10084254 -0.23481309  0.18576987 -0.36011033 -0.15726747 -0.25714889\n",
      " -0.14979669  0.02063898  0.04509171 -0.17239443  0.07287957 -0.0689103\n",
      " -0.13452462 -0.30697712  0.25404241 -0.28916471 -0.52061453  0.25252233\n",
      "  0.02177777 -0.10980907  0.37468422  0.35303004 -0.6211302  -0.42920064\n",
      " -0.14770647  0.00593404 -0.34735296  0.32245409 -0.19439024  0.1288847\n",
      " -0.0320947  -0.23008604 -0.10135548 -0.46962186  0.05184235  0.0609688\n",
      "  0.05632596  0.44769206 -0.38804349  0.24704844  0.16063684  0.0144203\n",
      " -0.03136574  0.11179177]\n"
     ]
    }
   ],
   "source": [
    "y_score = classifier.decision_function(X_test)\n",
    "print(y_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[20  4]\n",
      " [ 6 20]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.83      0.80        24\n",
      "           1       0.83      0.77      0.80        26\n",
      "\n",
      "    accuracy                           0.80        50\n",
      "   macro avg       0.80      0.80      0.80        50\n",
      "weighted avg       0.80      0.80      0.80        50\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "y_pred = classifier.predict(X_test)\n",
    "conf_mat = confusion_matrix(y_test, y_pred)\n",
    "print(conf_mat)\n",
    "rpt_result = classification_report(y_test, y_pred)\n",
    "print(rpt_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[18  6]\n",
      " [ 5 21]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.75      0.77        24\n",
      "           1       0.78      0.81      0.79        26\n",
      "\n",
      "    accuracy                           0.78        50\n",
      "   macro avg       0.78      0.78      0.78        50\n",
      "weighted avg       0.78      0.78      0.78        50\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred_new_threshold = classifier.decision_function(X_test) > -0.1\n",
    "conf_mat = confusion_matrix(y_test, y_pred_new_threshold)\n",
    "print(conf_mat)\n",
    "rpt_result = classification_report(y_test, y_pred_new_threshold)\n",
    "print(rpt_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[12 12]\n",
      " [ 2 24]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.50      0.63        24\n",
      "           1       0.67      0.92      0.77        26\n",
      "\n",
      "    accuracy                           0.72        50\n",
      "   macro avg       0.76      0.71      0.70        50\n",
      "weighted avg       0.76      0.72      0.71        50\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred_new_threshold = classifier.decision_function(X_test) > -0.2\n",
    "conf_mat = confusion_matrix(y_test, y_pred_new_threshold)\n",
    "print(conf_mat)\n",
    "rpt_result = classification_report(y_test, y_pred_new_threshold)\n",
    "print(rpt_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[23  1]\n",
      " [12 14]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.96      0.78        24\n",
      "           1       0.93      0.54      0.68        26\n",
      "\n",
      "    accuracy                           0.74        50\n",
      "   macro avg       0.80      0.75      0.73        50\n",
      "weighted avg       0.80      0.74      0.73        50\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred_new_threshold = classifier.decision_function(X_test) > 0.1\n",
    "conf_mat = confusion_matrix(y_test, y_pred_new_threshold)\n",
    "print(conf_mat)\n",
    "rpt_result = classification_report(y_test, y_pred_new_threshold)\n",
    "print(rpt_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[24  0]\n",
      " [17  9]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      1.00      0.74        24\n",
      "           1       1.00      0.35      0.51        26\n",
      "\n",
      "    accuracy                           0.66        50\n",
      "   macro avg       0.79      0.67      0.63        50\n",
      "weighted avg       0.80      0.66      0.62        50\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred_new_threshold = classifier.decision_function(X_test) > 0.2\n",
    "conf_mat = confusion_matrix(y_test, y_pred_new_threshold)\n",
    "print(conf_mat)\n",
    "rpt_result = classification_report(y_test, y_pred_new_threshold)\n",
    "print(rpt_result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
