# 📘 선형 회귀 프로젝트: 손실함수부터 학습까지

<hr style="opacity:0.2;"><br>

#### 🔧 학습 전제

- `numpy`, `pandas`, `matplotlib` 등을 자유롭게 활용 가능  
- 원-핫 인코딩 등의 간단한 전처리 기법 이해  
- 고등 수학 수준의 **도함수 정의**와 **미분 공식** 이해  
- 머신러닝 패러다임을 이해하고, 용어에 익숙함  

<hr style="opacity:0.2;"><br>

#### 🎯 학습 목표

- **입력 X / 정답 y / 예측값 prediction** 개념 이해  
- 손실함수의 필요성과 종류, 구현 방법 학습  
- 손실함수를 미분하여 얻는 **기울기의 의미** 이해  
  - 수치 미분, 해석 미분 두 가지 방식으로 구현  
- 손실함수를 줄이기 위한 **경사하강법(GD)**을 이용한 학습  
- **선형 회귀 전체 프로세스** 경험  
- `sklearn.linear_model.LinearRegression`을 활용한 간편한 학습  

<hr style="opacity:0.2;"><br>

# 🧪 Step 1. 단 하나의 정보로 예측해보기

#### (1) 맥북 중고가를 결정짓는 변수는 무엇일까?
- `사용한 연수(years)` 데이터 확인
- 예: `X = [1, 2, 3, 4]`, `y = [100, 90, 80, 70]`

#### (2) "모델"을 세운다는 것
- 데이터의 패턴을 수식으로 표현
- 예: `y = wx + b` 형태의 모델 설정

#### (3) 정확한 방정식이 아닌, "최적의 방정식"을 찾기
- **손실함수(loss function)** 정의
- 예: 평균제곱오차 (MSE)
  $$
  \text{MSE} = \frac{1}{n} \sum_{i=1}^n (y_i - \hat{y}_i)^2
  $$

#### (4) 손실함수를 줄이는 방향으로 학습
- **손실이 작을수록 예측이 정답에 가까움**

#### (5) 한 번에 못해도 괜찮아!
- **경사하강법(Gradient Descent)** 사용
- 기울기 방향으로 조금씩 이동하여 손실 최소화

<hr style="opacity:0.2;"><br>

# 🧮 Step 2. 여러 정보를 이용한 예측

#### (1) 다양한 특징으로 팁 예측
- 예: 성별, 인원 수, 총 금액 → 팁
- 다변수 입력: `X = [[남성, 3명, 20.5], [...]]`

#### (2) 손실함수 다시 정의하기
- 여전히 MSE 사용 가능
- 다차원 입력일 뿐, 손실 개념은 같음

#### (3) 직접 해보는 그래디언트 계산
- 해석적으로 편미분하여 기울기 계산
  $$
  \frac{\partial}{\partial w} \text{MSE},\quad \frac{\partial}{\partial b} \text{MSE}
  $$
- 또는 수치 미분 (작은 변화량으로 근사)

#### (
